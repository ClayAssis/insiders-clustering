{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color= 'blue'> Project: High Value Customer Identification (Insiders)</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T12:53:24.629168Z",
     "start_time": "2022-02-07T12:53:24.622757Z"
    },
    "hidden": true
   },
   "source": [
    "**Business Challange**\n",
    "\n",
    "A loyalty program of customers to increase sales frquency.\n",
    "\n",
    "**Business Planning (IOT)**\n",
    "\n",
    "**<font color= 'green'>Input**</font>\n",
    "\n",
    "**1. Business Problem**\n",
    "- Select the most valuable customers to join a loyalty program.\n",
    "\n",
    "**2. Dataset**\n",
    "    \n",
    "<u>One year e-commerce sales.</u>\n",
    "    \n",
    "   - Invoice No: Invoice number (A 6-digit integral number uniquely assigned to each transaction)\n",
    "\n",
    "   - Stock Code: Product (item) code\n",
    "\n",
    "   - Description: Product (item) name\n",
    "\n",
    "   - Quantity: The quantities of each product (item) per transaction\n",
    "\n",
    "   - Invoice Date: The day when each transaction was generated\n",
    "\n",
    "   - Unit Price: Unit price (Product price per unit)\n",
    "\n",
    "   - Customer ID: Customer number (Unique ID assigned to each customer)\n",
    "    \n",
    "   - Country: Country name (The name of the country where each customer resides)\n",
    "    \n",
    "**<font color= 'green'>Output**</font>\n",
    "- **1.** <u>Indicate customers who will be part of a loyalty program called Insiders.</u>\n",
    "     - List: client_id | is_insider\n",
    "             10323 |   yes\n",
    "             32413 |   no\n",
    "- **2.**<u> A report with the answers for the business questions.</u>\n",
    "    - Who are the customers eligible to join the program?\n",
    "    - How many customers will be part os this group?\n",
    "    - What are the main characteristics of these customers?\n",
    "    - What is the contribution percentage revenue from Insiders?\n",
    "    - What is the group's revenue expectation for the coming months?\n",
    "    - What are the condictions for select customers to join Insiders?\n",
    "    - What are the condictions for removing Insiders customers?\n",
    "    - What is the guarantee that the Insiders program is better than the rest of the base?\n",
    "    - What actions can the marketing team take to increase revenue?\n",
    "    \n",
    "**<font color= 'green'>Taks**</font>\n",
    "- <u>**1.** Who are the customers eligible to join the program?</u>\n",
    "  - What does it mean, to be elegible? What does high-value customers mean?\n",
    "  - Revenue: ticket, bascket size, high LTV (Lifetime Value), churn probability,high TVC prevision, purchasing propensity.\n",
    "  - Cost: lower return rate.\n",
    "  - Purchase experience: high average evaluation rate.\n",
    "     \n",
    "- <u>**2.** How many customers will be part os this group?</u>\n",
    "  - Total nambers of customers.\n",
    "  - % Insiders group.\n",
    "        \n",
    "- <u>**3.** What are the main characteristics of these customers?</u>\n",
    "  - Age\n",
    "  - Location\n",
    "  - Others characteristics.\n",
    "  - Ticket, bascket size, high LTV, churn probability,high TVC prevision, purchasing propensity.\n",
    "       \n",
    "        \n",
    "- <u>**4.** What is the contribution percentage revenue from Insiders?</u>\n",
    "   - Total revenue for the year.\n",
    "   - Insiders group revenue.\n",
    "         \n",
    "- <u>**5.** What is the group's revenue expectation for the coming months?</u>\n",
    "  - LTV Insisders group.\n",
    "  - Cohort analysis.\n",
    "        \n",
    "- <u>**6.** What are the condictions for select customers to join Insiders?</u>\n",
    "  - Define the periodicity\n",
    "  - The person needs to have similar characteristics with someone in the group.\n",
    "    \n",
    "- <u>**7.** What are the condictions for removing Insiders customers?</u>\n",
    "  - Define the periodicity\n",
    "  - The person doen't need to have similar characteristics with someone in the group.\n",
    "        \n",
    "- <u>**8.** What is the guarantee that the Insiders program is better than the rest of the base?</u>\n",
    "  - A/B test\n",
    "  - A/B bayesian test\n",
    "  - Hypothesis test\n",
    "        \n",
    "- <u>**9.** What actions can the marketing team take to increase revenue?</u>\n",
    "  - Discont\n",
    "  - Purchase preference\n",
    "  - Purchase shipping\n",
    "  - Company visit  \n",
    "        \n",
    "**<font color= 'green'>Benchmark Solutions**</font>\n",
    "\n",
    "- **Desk Research**\n",
    "   - RFM model (recency, frequency,, monetary): sorted data to have a RFM Score.\n",
    "   - Recency: How recently a customer has made a purchase\n",
    "   - Frequency: How often a customer makes a purchase\n",
    "   - Monetary Value: How much money a customer spends on purchases\n",
    "     \n",
    "- <u>example project:</u> https://guillaume-martin.github.io/rfm-segmentation-with-python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T01:12:03.703119Z",
     "start_time": "2022-02-15T01:12:03.690863Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy      as np\n",
    "import pandas     as pd\n",
    "import seaborn    as sns\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn          import cluster       as c\n",
    "from sklearn          import metrics       as m\n",
    "from sklearn          import mixture       as mx\n",
    "from sklearn          import ensemble      as en\n",
    "from sklearn          import preprocessing as pp\n",
    "from sklearn          import decomposition as dd\n",
    "from plotly           import express       as px\n",
    "from matplotlib       import pyplot        as plt\n",
    "from scipy.cluster    import hierarchy     as hc\n",
    "\n",
    "from datetime            import datetime\n",
    "from pandas_profiling    import ProfileReport\n",
    "from IPython.display     import Image, HTML\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:47.563079Z",
     "start_time": "2022-02-14T14:09:47.531009Z"
    }
   },
   "outputs": [],
   "source": [
    " def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()\n",
    "    \n",
    "jupyter_settings() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:52.112784Z",
     "start_time": "2022-02-14T14:09:51.667358Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df_raw = pd.read_csv('data/Ecommerce.csv')\n",
    "\n",
    "# drop extra column\n",
    "df_raw = df_raw.drop(columns = ['Unnamed: 8'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1.0. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:52.362082Z",
     "start_time": "2022-02-14T14:09:52.337523Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.1. Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:52.840866Z",
     "start_time": "2022-02-14T14:09:52.832962Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_new = ['invoice_no', 'stock_code', 'description', 'quantity', 'invoice_date',\n",
    "       'unit_price', 'customer_id', 'country']\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T19:34:06.250066Z",
     "start_time": "2022-02-07T19:34:06.246803Z"
    },
    "hidden": true
   },
   "source": [
    "## 1.2. Data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:53.255152Z",
     "start_time": "2022-02-14T14:09:53.249520Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Number of Rows: {}'.format(df1.shape[0]))\n",
    "print('Number of Columns: {}'.format(df1.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.3. Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:53.661901Z",
     "start_time": "2022-02-14T14:09:53.652586Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:54.060103Z",
     "start_time": "2022-02-14T14:09:53.841528Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1['invoice_no'] = df1['invoice_no'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:54.061689Z",
     "start_time": "2022-02-14T14:09:54.042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1['stock_code'] = df1['stock_code'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.4. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:54.555774Z",
     "start_time": "2022-02-14T14:09:54.433414Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.5. Replace NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:54.908333Z",
     "start_time": "2022-02-14T14:09:54.838132Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_missing = df1.loc[df1['customer_id'].isna(),:]\n",
    "df_not_missing = df1.loc[~df1['customer_id'].isna(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:55.494552Z",
     "start_time": "2022-02-14T14:09:55.051121Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create reference\n",
    "df_backup = pd.DataFrame(df_missing['invoice_no'].drop_duplicates())\n",
    "df_backup['customer_id'] = np.arange(19000, 19000+len(df_backup),1)\n",
    "\n",
    "# merge original with reference dataframe\n",
    "df1 = pd.merge(df1, df_backup, on = 'invoice_no', how= 'left')\n",
    "\n",
    "# coalesce\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first(df1['customer_id_y'])\n",
    "\n",
    "# drop extra columns\n",
    "df1 = df1.drop(columns=['customer_id_x','customer_id_y'], axis=1)\n",
    "   \n",
    "df1.head()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:55.584795Z",
     "start_time": "2022-02-14T14:09:55.495634Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# No NaN in 'customer_id'\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.6. Change dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:56.108569Z",
     "start_time": "2022-02-14T14:09:55.999014Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# invoice_date\n",
    "df1[\"invoice_date\"] = pd.to_datetime(df1[\"invoice_date\"],infer_datetime_format=True)\n",
    "\n",
    "# customer_id\n",
    "df1['customer_id'] = df1['customer_id'].astype(int)\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.7. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:56.512329Z",
     "start_time": "2022-02-14T14:09:56.473333Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes(include =['int64', 'float64'])\n",
    "cat_attributes = df1.select_dtypes(exclude = ['int64', 'float64', 'datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:56.777212Z",
     "start_time": "2022-02-14T14:09:56.694062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " # central tendency - mean, median\n",
    "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "             \n",
    "# dispersion - desvio padrão, minimo, maximo, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T\n",
    "d2 = pd.DataFrame( num_attributes.apply( np.min ) ).T\n",
    "d3 = pd.DataFrame( num_attributes.apply( np.max ) ).T\n",
    "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T\n",
    "\n",
    "# concatenate\n",
    "m = pd.concat( [d2, d3, d4, ct1, ct2, d1, d5, d6] ).T.reset_index()\n",
    "m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'mediana', 'std', 'skew', 'kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.7.1.1. Numerical Attributes - Investigating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T17:48:46.911147Z",
     "start_time": "2022-02-09T17:48:46.903035Z"
    },
    "hidden": true
   },
   "source": [
    "1. Could be negative quantity, return?\n",
    "2. Unit price = 0. Could it be sales?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.7.2. Categorical Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Invoice number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:58.609031Z",
     "start_time": "2022-02-14T14:09:58.123399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cat_attributes['invoice_no'].astype(int)  -> Data contains 'invoice_no' with numbers and letters.\n",
    "df_letter_invoices = df1.loc[df1['invoice_no'].apply(lambda x: bool(re.search( '[^0-9]+', x ))), :]\n",
    "len(df_letter_invoices)\n",
    "\n",
    "print('Total number of invoices:{}'.format(len(df_letter_invoices)))\n",
    "print('Total number os negative quantity:{}'.format(len(df_letter_invoices[df_letter_invoices['quantity']< 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Stock Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:59.028417Z",
     "start_time": "2022-02-14T14:09:58.613232Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check stock codes only characters\n",
    "df1.loc[df1['stock_code'].apply( lambda x: bool( re.search( '^[a-zA-Z]+$', x ) ) ), 'stock_code'].unique()\n",
    "\n",
    "# Action:\n",
    "## 1. Remove stock_code in ['POST', 'D', 'M', 'PADS', 'DOT', 'CRUK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:59.337785Z",
     "start_time": "2022-02-14T14:09:59.334211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Action: Delete description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:09:59.976773Z",
     "start_time": "2022-02-14T14:09:59.922713Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df1['country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:00.259018Z",
     "start_time": "2022-02-14T14:10:00.164981Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1['country'].value_counts(normalize = True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:00.482597Z",
     "start_time": "2022-02-14T14:10:00.407034Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1[['customer_id', 'country']].drop_duplicates().groupby('country').count().reset_index().sort_values('customer_id', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2.0. Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:00.944887Z",
     "start_time": "2022-02-14T14:10:00.914465Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:01.341635Z",
     "start_time": "2022-02-14T14:10:01.332563Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:01.813520Z",
     "start_time": "2022-02-14T14:10:01.569426Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# === Numerical attributes ====\n",
    "df2 = df2.loc[df2['unit_price'] >= 0.04, :]\n",
    "\n",
    "# === Categorical attributes ====\n",
    "df2 = df2[~df2['stock_code'].isin( ['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY', 'DCGSSGIRL', 'PADS', 'B', 'CRUK'] ) ]\n",
    "\n",
    "# description\n",
    "df2 = df2.drop( columns='description', axis=1 )\n",
    "\n",
    "# map -  \n",
    "df2 = df2[~df2['country'].isin( ['European Community', 'Unspecified' ] ) ]\n",
    "\n",
    "# bad users - outlier\n",
    "df2 = df2[~df2['customer_id'].isin( [16446] )]\n",
    "\n",
    "# quantity\n",
    "df2_returns = df2.loc[df1['quantity'] < 0, :]\n",
    "df2_purchase = df2.loc[df1['quantity'] >= 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3.0. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:02.021403Z",
     "start_time": "2022-02-14T14:10:02.002215Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:02.227720Z",
     "start_time": "2022-02-14T14:10:02.224890Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Feature Ideas:\n",
    "## 1) Moving Average - 7d, 14d, 30d\n",
    "## 2) Purchase quantity by month, before the 15th and after the 15th.\n",
    "## 3) Average Financial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.1. Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:02.718083Z",
     "start_time": "2022-02-14T14:10:02.683676Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data reference\n",
    "df_ref = df3.drop(['invoice_no', 'stock_code', 'quantity', 'invoice_date', 'unit_price', 'country'],\n",
    "                   axis =1 ).drop_duplicates( ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.1. Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:03.198336Z",
     "start_time": "2022-02-14T14:10:03.141793Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Gross Revenue\n",
    "df2_purchase.loc[:,'gross_revenue'] = df2_purchase.loc[:,'quantity'] * df2_purchase.loc[:,'unit_price']\n",
    "\n",
    "# Monetary\n",
    "df_monetary = df2_purchase.loc[:,['customer_id', 'gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "df_ref = pd.merge(df_ref, df_monetary, on = 'customer_id', how = 'left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.2. Recency - Day from last purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:03.900022Z",
     "start_time": "2022-02-14T14:10:03.854273Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " # Recency - Last day purchase\n",
    "df_recency = df2_purchase.loc[:, ['customer_id', 'invoice_date']].groupby( 'customer_id' ).max().reset_index()\n",
    "df_recency['recency_days'] = ( df2['invoice_date'].max() - df_recency['invoice_date'] ).dt.days\n",
    "df_recency = df_recency[['customer_id', 'recency_days']].copy()\n",
    "df_ref = pd.merge( df_ref, df_recency, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.3. Quantity of purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:04.437905Z",
     "start_time": "2022-02-14T14:10:04.358749Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Frequency - It depens on product returns\n",
    "df_freq =(df2_purchase.loc[:,['customer_id', 'invoice_no']].drop_duplicates()\n",
    "                                                          .groupby('customer_id')\n",
    "                                                          .count()\n",
    "                                                          .reset_index()\n",
    "                                                          .rename(columns={'invoice_no': 'quantity_invoices'}))\n",
    "df_ref = pd.merge( df_ref, df_freq, on = 'customer_id', how ='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.4. Quantity of items purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:05.397462Z",
     "start_time": "2022-02-14T14:10:05.352991Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_freq = (df2_purchase.loc[:,['customer_id', 'quantity']].groupby('customer_id')\n",
    "                                                        .sum()\n",
    "                                                        .reset_index()\n",
    "                                                        .rename(columns={'quantity': 'quantity_items'}))\n",
    "                                                        \n",
    "                                                        \n",
    "df_ref = pd.merge( df_ref, df_freq, on = 'customer_id', how ='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.5. Quantity of products purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:05.827966Z",
     "start_time": "2022-02-14T14:10:05.764615Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_freq = (df2_purchase.loc[:,['customer_id', 'stock_code']].groupby('customer_id')\n",
    "                                                        .count()\n",
    "                                                        .reset_index()\n",
    "                                                        .rename(columns={'stock_code': 'quantity_products'}))\n",
    "                                                        \n",
    "                                                        \n",
    "df_ref = pd.merge( df_ref, df_freq, on = 'customer_id', how ='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3 .1.6. Average Ticket Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:06.203664Z",
     "start_time": "2022-02-14T14:10:06.167262Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Average Ticket\n",
    "df_avg_ticket = df2_purchase[['customer_id', 'gross_revenue']].groupby('customer_id').mean().reset_index().rename(columns={'gross_revenue': 'avg_ticket'})\n",
    "df_ref = pd.merge( df_ref, df_avg_ticket, on = 'customer_id', how = 'left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.7. Average Recency Days: range between purchases / total purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:07.119809Z",
     "start_time": "2022-02-14T14:10:06.595024Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Average recency days\n",
    "df_aux = df2[['customer_id', 'invoice_date']].drop_duplicates().sort_values(['customer_id', 'invoice_date'], ascending=['False', 'False'])\n",
    "df_aux['next_customer_id'] = df_aux['customer_id'].shift() # next customer\n",
    "df_aux['previous_date'] = df_aux['invoice_date'].shift() # next invoice date\n",
    "\n",
    "df_aux['avg_recency_days'] = df_aux.apply(lambda x: (x['invoice_date'] - x['previous_date']).days if x['customer_id'] ==x['next_customer_id'] else np.nan, axis=1 )\n",
    "\n",
    "df_aux = df_aux.drop( ['invoice_date', 'next_customer_id', 'previous_date'], axis=1 ).dropna()\n",
    "\n",
    "# average recency\n",
    "df_avg_recency_days = df_aux.groupby( 'customer_id' ).mean().reset_index()\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge(df_ref, df_avg_recency_days, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.8. Frequency Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:07.722527Z",
     "start_time": "2022-02-14T14:10:07.120922Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_aux = ( df2_purchase[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates()\n",
    "                                                             .groupby( 'customer_id')\n",
    "                                                             .agg( max_ = ( 'invoice_date', 'max' ), \n",
    "                                                                   min_ = ( 'invoice_date', 'min' ),\n",
    "                                                                   days_= ( 'invoice_date', lambda x: ( ( x.max() - x.min() ).days ) + 1 ),\n",
    "                                                                   buy_ = ( 'invoice_no', 'count' ) ) ).reset_index()\n",
    "# Frequency\n",
    "df_aux['frequency'] = df_aux[['buy_', 'days_']].apply( lambda x: x['buy_'] / x['days_'] if  x['days_'] != 0 else 0, axis=1 )\n",
    "\n",
    "# Merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'frequency']], on='customer_id', how='left' )\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.9. Number of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:07.730870Z",
     "start_time": "2022-02-14T14:10:07.723702Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:07.772606Z",
     "start_time": "2022-02-14T14:10:07.759265Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Number of Returns\n",
    "df_returns = df2_returns[['customer_id', 'quantity']].groupby( 'customer_id' ).sum().reset_index().rename( columns={'quantity':'quantity_returns'} )\n",
    "df_returns['quantity_returns'] = df_returns['quantity_returns'] * -1\n",
    "\n",
    "df_ref = pd.merge( df_ref, df_returns, how='left', on='customer_id' )\n",
    "df_ref.loc[df_ref['quantity_returns'].isna(), 'quantity_returns'] = 0\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.2.0. Basket Size - Quantity items per basket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Invoice No = purchase\n",
    "- Stock Code = product\n",
    "- Quantity = Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:08.532642Z",
     "start_time": "2022-02-14T14:10:08.441054Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_aux = (df2_purchase.loc[:,['customer_id', 'invoice_no', 'quantity']].groupby('customer_id')\n",
    "                                                           .agg(n_purchase=('invoice_no', 'nunique'),\n",
    "                                                                n_products=('quantity', 'sum'))\n",
    "                                                            .reset_index())\n",
    "# calculation\n",
    "df_aux['avg_basket_size'] = df_aux['n_products']/df_aux['n_purchase']\n",
    "\n",
    "#merge\n",
    "df_ref = pd.merge(df_ref, df_aux[['customer_id', 'avg_basket_size']], how='left', on='customer_id')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.2.1. Unique Basket Size - Quantity of differents products per purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Invoice No = purchase\n",
    "- Stock Code = product\n",
    "- Quantity = Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:09.302484Z",
     "start_time": "2022-02-14T14:10:09.125700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_aux = (df2_purchase.loc[:,['customer_id', 'invoice_no', 'stock_code']].groupby('customer_id')\n",
    "                                                           .agg(n_purchase=('invoice_no', 'nunique'),\n",
    "                                                                n_products=('stock_code', 'nunique'))\n",
    "                                                            .reset_index())\n",
    "# calculation\n",
    "df_aux['avg_unique_basket_size'] = df_aux['n_products']/df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge(df_ref, df_aux[['customer_id', 'avg_unique_basket_size']], how='left', on='customer_id')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:09.362347Z",
     "start_time": "2022-02-14T14:10:09.351420Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:10.271873Z",
     "start_time": "2022-02-14T14:10:10.250122Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df_ref.dropna()\n",
    "df4.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T17:47:15.590785Z",
     "start_time": "2022-02-12T17:47:15.571970Z"
    }
   },
   "source": [
    "**Notes.01**\n",
    "1) What do we look for in a clustering problem?\n",
    "- Cohesive and separate cluster.\n",
    "- Variability\n",
    "    - Metrics:\n",
    "        - Min, max, range (dispersion).\n",
    "        - Mean and Median.\n",
    "        - Standard deviation( std) and variance.\n",
    "        - Coefficient of variation (CV) = std/mean\n",
    "Obs: The cluster type differs with each type of business problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T14:52:10.428490Z",
     "start_time": "2022-02-13T14:52:10.416378Z"
    }
   },
   "source": [
    "**Explore/Delete**\n",
    "\n",
    "**1.** Gross Revenue - ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:15.311025Z",
     "start_time": "2022-02-14T14:10:15.307686Z"
    }
   },
   "outputs": [],
   "source": [
    "#profile = ProfileReport(df4)\n",
    "#profile.to_file('output_v2.html')\n",
    "\n",
    "# to visualize: output/output_v2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Gross Revenue/Quantity of Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:17.514177Z",
     "start_time": "2022-02-14T14:10:17.492053Z"
    }
   },
   "outputs": [],
   "source": [
    "# outlier?\n",
    "df4[df4['customer_id']==14646]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:18.328802Z",
     "start_time": "2022-02-14T14:10:18.304057Z"
    }
   },
   "outputs": [],
   "source": [
    "df3[df3['customer_id']==14646].sort_values('quantity', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T18:30:26.668497Z",
     "start_time": "2022-02-12T18:30:26.662537Z"
    }
   },
   "source": [
    "### 4.1.2. Quantity of Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:19.471259Z",
     "start_time": "2022-02-14T14:10:19.449484Z"
    }
   },
   "outputs": [],
   "source": [
    "# outlier?\n",
    "df4[df4['quantity_products']==7838]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:19.705527Z",
     "start_time": "2022-02-14T14:10:19.680969Z"
    }
   },
   "outputs": [],
   "source": [
    "df3[df3['customer_id']==17841].sort_values('quantity', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. Average Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:20.261669Z",
     "start_time": "2022-02-14T14:10:20.244009Z"
    }
   },
   "outputs": [],
   "source": [
    "# outlier ===== Impotant =====\n",
    "# quantaty_items: 80997.0\n",
    "# quantaty_returns: 80995.0\n",
    "df4[df4['avg_ticket']==56157.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:21.054555Z",
     "start_time": "2022-02-14T14:10:21.038465Z"
    }
   },
   "outputs": [],
   "source": [
    "df3[df3['customer_id']==16446] # This customer_id is an outlier. \"removed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4. Frequecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:22.602396Z",
     "start_time": "2022-02-14T14:10:22.579302Z"
    }
   },
   "outputs": [],
   "source": [
    "df4[df4['frequency']==17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:23.353282Z",
     "start_time": "2022-02-14T14:10:23.329842Z"
    }
   },
   "outputs": [],
   "source": [
    "df3[df3['customer_id']==17850].sort_values('quantity', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5. Average Basket Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:23.869172Z",
     "start_time": "2022-02-14T14:10:23.852507Z"
    }
   },
   "outputs": [],
   "source": [
    "df4[df4['avg_basket_size']==40498.5] # customer_id 16446 is an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:24.096341Z",
     "start_time": "2022-02-14T14:10:24.072142Z"
    }
   },
   "outputs": [],
   "source": [
    "df3[df3['customer_id']==17850].sort_values('quantity', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:25.177824Z",
     "start_time": "2022-02-14T14:10:25.170094Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['customer_id']\n",
    "df42 = df4.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:52.544830Z",
     "start_time": "2022-02-14T14:10:25.818508Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,12))\n",
    "sns.pairplot(df42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T17:28:48.229533Z",
     "start_time": "2022-02-13T17:28:48.215801Z"
    }
   },
   "source": [
    "**Notes**\n",
    "\n",
    "**1.** Frequency has low variance\n",
    "\n",
    "**2.** Avg Ticket has low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Space Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PCA : axis variability reduction\n",
    "2. UMAP: variability reduction via Baysean system   \n",
    "3. t-SNE: \n",
    "4. Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:15.052774Z",
     "start_time": "2022-02-14T14:12:15.043005Z"
    }
   },
   "outputs": [],
   "source": [
    "df43 = df4.drop(columns = ['customer_id'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:15.405719Z",
     "start_time": "2022-02-14T14:12:15.356022Z"
    }
   },
   "outputs": [],
   "source": [
    "# MinMax Scaler\n",
    "# from sklearn import prepocessing as pp\n",
    "mm = pp.MinMaxScaler()\n",
    "\n",
    "df43['gross_revenue']          = mm.fit_transform(df43[['gross_revenue']])\n",
    "df43['recency_days']           = mm.fit_transform(df43[['recency_days']])\n",
    "df43['quantity_invoices']      = mm.fit_transform(df43[['quantity_invoices']])\n",
    "df43['quantity_items']         = mm.fit_transform(df43[['quantity_items']])\n",
    "df43['quantity_products']      = mm.fit_transform(df43[['quantity_products']])\n",
    "df43['avg_ticket']             = mm.fit_transform(df43[['avg_ticket']])\n",
    "df43['avg_recency_days']       = mm.fit_transform(df43[['avg_recency_days']])\n",
    "df43['frequency']              = mm.fit_transform(df43[['frequency']])\n",
    "df43['quantity_returns']       = mm.fit_transform(df43[['quantity_returns']])\n",
    "df43['avg_basket_size']        = mm.fit_transform(df43[['avg_basket_size']])\n",
    "df43['avg_unique_basket_size'] = mm.fit_transform(df43[['avg_unique_basket_size']])\n",
    "\n",
    "X = df43.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:16.401437Z",
     "start_time": "2022-02-14T14:12:16.396814Z"
    }
   },
   "outputs": [],
   "source": [
    "#from sklearn import decomposition as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:16.657648Z",
     "start_time": "2022-02-14T14:12:16.652092Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:22.934337Z",
     "start_time": "2022-02-14T14:12:22.654646Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = dd.PCA(n_components = X.shape[1])\n",
    "\n",
    "principal_components = pca.fit_transform(X)\n",
    "\n",
    "# plot explained variable\n",
    "features = range(pca.n_components_)\n",
    "\n",
    "plt.bar(features, pca.explained_variance_ratio_, color='black')\n",
    "\n",
    "# pca component\n",
    "df_pca = pd.DataFrame(principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:23.236858Z",
     "start_time": "2022-02-14T14:12:23.077859Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x= 0, y=1, data=df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:35.535860Z",
     "start_time": "2022-02-14T14:12:24.297797Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install llvmlite==0.37.0rc2 --ignore-installed\n",
    "#!pip install umap-learn\n",
    "#import umap.umap_ as umap\n",
    "\n",
    "# UMAP: cluster designed with high dimensionality\n",
    "\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding = reducer.fit_transform(X)\n",
    "\n",
    "#embedding\n",
    "df_pca['embedding_x'] = embedding[:, 0]\n",
    "df_pca['embedding_y'] = embedding[:, 1]\n",
    "\n",
    "# plot UMAP\n",
    "sns.scatterplot(x='embedding_x',\n",
    "                y='embedding_y',\n",
    "                data= df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:43.626607Z",
     "start_time": "2022-02-14T14:12:35.537110Z"
    }
   },
   "outputs": [],
   "source": [
    "#from sklearn.manifold import TSNE\n",
    "reducer = TSNE(n_components=2,n_jobs=-1,random_state=42)\n",
    "embedding = reducer.fit_transform(X)\n",
    "\n",
    "#embedding\n",
    "df_pca['embedding_x'] = embedding[:, 0]\n",
    "df_pca['embedding_y'] = embedding[:, 1]\n",
    "\n",
    "# plot UMAP\n",
    "sns.scatterplot(x='embedding_x',\n",
    "                y='embedding_y',\n",
    "                data= df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. Tree-Based Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:45.040052Z",
     "start_time": "2022-02-14T14:12:43.628507Z"
    }
   },
   "outputs": [],
   "source": [
    "df4.head()\n",
    "X = df4.drop(columns =['customer_id', 'gross_revenue'], axis=1)\n",
    "y = df4['gross_revenue'] # --> “target variable” \n",
    "\n",
    "# model definition\n",
    "# from sklearn import ensemble as en\n",
    "rf_model = en.RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# model training\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Leaf  the result \"df_leaf\" is a space, but to verify it necessery reduce the dimensionality to 2 dimensions --> Reduzer dimensionality with UMAP.\n",
    "df_leaf = pd.DataFrame(rf_model.apply(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:45.043515Z",
     "start_time": "2022-02-14T14:12:45.041252Z"
    }
   },
   "outputs": [],
   "source": [
    "df_leaf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:12:45.065111Z",
     "start_time": "2022-02-14T14:12:45.044401Z"
    }
   },
   "outputs": [],
   "source": [
    "# The result \"df_leaf\" is a space, but to verify it necessery reduce the dimensionality to 2 dimensions --> Reduzer dimensionality with UMAP.\n",
    "df_leaf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:03:02.919210Z",
     "start_time": "2022-02-15T18:02:54.072304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reduzer dimensionality\n",
    "reducer = umap.UMAP( random_state=42 )\n",
    "embedding = reducer.fit_transform( df_leaf )\n",
    "\n",
    "# embedding\n",
    "df_tree = pd.DataFrame()\n",
    "df_tree['embedding_x'] = embedding[:, 0]\n",
    "df_tree['embedding_y'] = embedding[:, 1]\n",
    "\n",
    "# plot UMAP\n",
    "sns.scatterplot( x='embedding_x', \n",
    "                 y='embedding_y', \n",
    "                 data=df_tree )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:03:51.237999Z",
     "start_time": "2022-02-15T18:03:51.231817Z"
    }
   },
   "outputs": [],
   "source": [
    "#df5 = df4.copy()\n",
    "#df5_aux = df4.copy()\n",
    "df5 = df_tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:04:03.918235Z",
     "start_time": "2022-02-15T18:04:03.912569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Scaler\n",
    "#from sklearn import preprocessing as pp\n",
    "#mm = pp.MinMaxScaler()\n",
    "#ss = pp.StandardScaler()\n",
    "#rs = pp.RobustScaler()\n",
    "\n",
    "#df5['gross_revenue']          = mm.fit_transform(df5[['gross_revenue']])\n",
    "#df5['recency_days']           = mm.fit_transform(df5[['recency_days']])\n",
    "# df5['quantity_invoices']      = mm.fit_transform(df5[['quantity_invoices']])\n",
    "# df5['quantity_items']         = mm.fit_transform(df5[['quantity_items']])\n",
    "#df5['quantity_products']      = mm.fit_transform(df5[['quantity_products']])\n",
    "# df5['avg_ticket']             = mm.fit_transform(df5[['avg_ticket']])\n",
    "# df5['avg_recency_days']       = mm.fit_transform(df5[['avg_recency_days']])\n",
    "#df5['frequency']              = mm.fit_transform(df5[['frequency']])\n",
    "#df5['quantity_returns']       = mm.fit_transform(df5[['quantity_returns']])\n",
    "# df5['avg_basket_size']        = mm.fit_transform(df5[['avg_basket_size']])\n",
    "# df5['avg_unique_basket_size'] = mm.fit_transform(df5[['avg_unique_basket_size']])\n",
    "    \n",
    "#variable = 'avg_unique_basket_size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:04:05.584289Z",
     "start_time": "2022-02-15T18:04:05.579141Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Data as is\n",
    "#print('Min:{} - Max:{}'.format(df5_aux[variable].min(), df5_aux[variable].max()))\n",
    "#sns.displot(df5_aux[variable]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:04:05.861188Z",
     "start_time": "2022-02-15T18:04:05.857955Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Data Standardization/Rescale\n",
    "#print('Min:{} - Max:{}'.format(df5[variable].min(), df5[variable].max()))\n",
    "#sns.displot(df5[variable]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:04:35.633157Z",
     "start_time": "2022-02-15T18:04:35.630538Z"
    }
   },
   "outputs": [],
   "source": [
    "# BoxPlot\n",
    "#sns.boxplot(df5_aux[variable]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:04:58.562872Z",
     "start_time": "2022-02-15T18:04:58.559033Z"
    }
   },
   "outputs": [],
   "source": [
    "#cols_selected = ['customer_id', 'gross_revenue', 'recency_days', 'quantity_products', 'frequency', 'quantity_returns']\n",
    "#df6 = df5[ cols_selected ].copy()\n",
    "df6 = df_tree.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0. Hyperparameter Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:05:10.493498Z",
     "start_time": "2022-02-15T18:05:10.489743Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = df6.drop( columns=['customer_id'] )\n",
    "X = df_tree.copy()#df6.drop( columns=['customer_id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:05:13.051394Z",
     "start_time": "2022-02-15T18:05:13.032886Z"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:05:51.577702Z",
     "start_time": "2022-02-15T18:05:51.569888Z"
    }
   },
   "outputs": [],
   "source": [
    "#clusters = [2, 3, 4, 5, 6, 7, 8, 9]\n",
    "clusters = np.arange( 2, 25, 1)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:06:04.360223Z",
     "start_time": "2022-02-15T18:06:04.356645Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:06:08.384490Z",
     "start_time": "2022-02-15T18:06:04.763710Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_list = []\n",
    "for k in clusters:\n",
    "    # model definition\n",
    "    kmeans_model = c.KMeans( n_clusters=k )\n",
    "\n",
    "    # model training\n",
    "    kmeans_model.fit( X )\n",
    "\n",
    "    # model predict\n",
    "    labels = kmeans_model.predict( X )\n",
    "\n",
    "    # model performance\n",
    "    sil = m.silhouette_score( X, labels, metric='euclidean' )\n",
    "    kmeans_list.append( sil )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:06:08.526284Z",
     "start_time": "2022-02-15T18:06:08.386010Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(clusters, kmeans_list, linestyle='--', marker='o', color='b')\n",
    "plt.xlabel('K');\n",
    "plt.ylabel('Silhouette Score');\n",
    "plt.title('Silhouette Score x K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:06:45.878358Z",
     "start_time": "2022-02-15T18:06:43.539585Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn import mixture as mx\n",
    "\n",
    "gmm_list = []\n",
    "for k in clusters:\n",
    "    # model definition\n",
    "    gmm_model = mx.GaussianMixture(n_components=k)\n",
    "\n",
    "    # model training\n",
    "    gmm_model.fit(X)\n",
    "\n",
    "    # model predict\n",
    "    labels = gmm_model.predict(X)\n",
    "\n",
    "    # model performance\n",
    "    sil = m.silhouette_score(X, labels, metric='euclidean')\n",
    "    gmm_list.append(sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:06:45.882452Z",
     "start_time": "2022-02-15T18:06:45.879793Z"
    }
   },
   "outputs": [],
   "source": [
    "gmm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:06:46.655065Z",
     "start_time": "2022-02-15T18:06:46.477368Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(clusters, gmm_list, linestyle='--', marker='o', color='b')\n",
    "plt.xlabel('K');\n",
    "plt.ylabel('Silhouette Score');\n",
    "plt.title('Silhouette Score x K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T16:53:22.783206Z",
     "start_time": "2022-02-15T16:53:22.615625Z"
    }
   },
   "outputs": [],
   "source": [
    "# from scipy.cluster import hierarchy as hc\n",
    "\n",
    "# model definition and training\n",
    "hc_model = hc.linkage(X, 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:07:22.379043Z",
     "start_time": "2022-02-15T18:07:22.374207Z"
    }
   },
   "outputs": [],
   "source": [
    "#hc.dendrogram(\n",
    "    #hc_model,\n",
    "    #leaf_rotation = 90,\n",
    "    #leaf_font_size=8\n",
    "#)\n",
    "\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:07:32.102669Z",
     "start_time": "2022-02-15T18:07:32.098122Z"
    }
   },
   "outputs": [],
   "source": [
    "#hc.dendrogram(\n",
    "    #hc_model,\n",
    "    #truncate_mode='lastp',\n",
    "    #p=12,\n",
    "    #leaf_rotation = 90,\n",
    "   # leaf_font_size=8,\n",
    "    #show_contracted=True\n",
    "#)\n",
    "\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1. HClustering Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:07:55.769858Z",
     "start_time": "2022-02-15T18:07:52.090829Z"
    }
   },
   "outputs": [],
   "source": [
    "hc_list = []\n",
    "for k in clusters:\n",
    "    # model definition and training\n",
    "    hc_model = hc.linkage(X, 'ward')\n",
    "\n",
    "    # model predict\n",
    "    labels = hc.fcluster(hc_model, k, criterion='maxclust')\n",
    "\n",
    "    # metrics\n",
    "    sil = m.silhouette_score(X, labels, metric='euclidean')\n",
    "    hc_list.append(sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:08:16.367493Z",
     "start_time": "2022-02-15T18:08:16.196130Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(clusters, hc_list, linestyle='--', marker='o', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:08:35.128834Z",
     "start_time": "2022-02-15T18:08:34.965927Z"
    }
   },
   "outputs": [],
   "source": [
    "eps=2\n",
    "min_samples=20\n",
    "\n",
    "# model definition\n",
    "dbscan_model = c.DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "# model training & predict\n",
    "labels = dbscan_model.fit_predict(X)\n",
    "\n",
    "sil = m.silhouette_score(X, labels, metric='euclidean')\n",
    "print('Silhouette Score: {}'.format(sil))\n",
    "print('Number of Clusters: {}'.format(len(unique(labels))))\n",
    "print(unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:08:44.389555Z",
     "start_time": "2022-02-15T18:08:44.384492Z"
    }
   },
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "#sklearn.__version__\n",
    "#'0.16.1'\n",
    "#from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:08:44.925124Z",
     "start_time": "2022-02-15T18:08:44.894262Z"
    }
   },
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=min_samples).fit(X)\n",
    "distances, indices = neighbors.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:08:45.654513Z",
     "start_time": "2022-02-15T18:08:45.400106Z"
    }
   },
   "outputs": [],
   "source": [
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "\n",
    "plt.subplot(1, 2, 1 )\n",
    "plt.plot(distances)\n",
    "\n",
    "plt.subplot(1, 2, 2 )\n",
    "plt.plot(distances[2000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:09:39.380729Z",
     "start_time": "2022-02-15T18:09:39.374435Z"
    }
   },
   "outputs": [],
   "source": [
    "dbscan_list = [0.663586, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:10:21.943470Z",
     "start_time": "2022-02-15T18:10:21.899660Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame( \n",
    "    {'KMeans': kmeans_list, \n",
    "     'GMM': gmm_list, \n",
    "     'HC': hc_list}\n",
    "     #'DBSCAN': dbscan_list}\n",
    ").T\n",
    "\n",
    "df_results.columns = clusters\n",
    "df_results.style.highlight_max(color='yellow', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:00:56.384518Z",
     "start_time": "2022-02-14T14:00:56.379755Z"
    }
   },
   "source": [
    "## 7.6. Silhouette Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:10:47.596180Z",
     "start_time": "2022-02-15T18:10:45.635641Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( 3, 2 )\n",
    "fig.set_size_inches( 25, 20 )\n",
    "\n",
    "for k in clusters:\n",
    "    q, mod = divmod( k, 2 )\n",
    "    \n",
    "    ax[q-1, mod].set_xlim( [ -0.1, 1] )\n",
    "    ax[q-1, mod].set_ylim( [ 0, len( X ) + ( k+1 )*10] )\n",
    "    \n",
    "    # model definition & training\n",
    "    hc_model = hc.linkage( X, 'ward' )\n",
    "\n",
    "    # model predict\n",
    "    labels = hc.fcluster( hc_model, k, criterion='maxclust' )\n",
    "\n",
    "    # performance\n",
    "    ss = m.silhouette_score( X, labels, metric='euclidean' )\n",
    "    print( ' For K = {}. Silhouette Score: {}'.format( k, ss ) )\n",
    "\n",
    "    samples_silhouette_values = m.silhouette_samples( X, labels )\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range( k ):\n",
    "\n",
    "        # select clusters\n",
    "        ith_samples_silhouette_values = samples_silhouette_values[ labels == i]\n",
    "        \n",
    "        # sort values\n",
    "        ith_samples_silhouette_values.sort()\n",
    "\n",
    "        # size clusters\n",
    "        size_cluster_i = ith_samples_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        \n",
    "        cmap = cm.get_cmap( 'Spectral' )\n",
    "        color = cmap( i / k )\n",
    "\n",
    "        ax[q-1, mod].fill_betweenx( np.arange( y_lower, y_upper ), 0, ith_samples_silhouette_values  )\n",
    "        \n",
    "        y_lower = y_upper + 10\n",
    "        \n",
    "    ax[q-1, mod].set_yticks([])\n",
    "    ax[q-1, mod].set_xticks( [-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T17:02:26.665080Z",
     "start_time": "2022-02-15T17:02:26.560493Z"
    }
   },
   "outputs": [],
   "source": [
    " ## model definition\n",
    "#k = 8\n",
    "#kmeans = c.KMeans( init='random', n_clusters=k, n_init=10, max_iter=300 )\n",
    "#\n",
    "## model training\n",
    "#kmeans.fit( X )\n",
    "#\n",
    "## clustering\n",
    "#labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:11:42.927885Z",
     "start_time": "2022-02-15T18:11:42.875489Z"
    }
   },
   "outputs": [],
   "source": [
    "k=9\n",
    "# model definition\n",
    "kmeans = mx.GaussianMixture( n_components=k )\n",
    "\n",
    "# model training\n",
    "kmeans.fit( X )\n",
    "\n",
    "# model predict\n",
    "labels = kmeans.predict( X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:11:59.315111Z",
     "start_time": "2022-02-15T18:11:59.290455Z"
    }
   },
   "outputs": [],
   "source": [
    "# WSS (Within- cluster sum of square)\n",
    "print('WSS value: {}'.format( kmeans.inertia_))\n",
    "\n",
    "from sklearn import metrics as m\n",
    "# SS (Silhouette Score)\n",
    "print('SS value: {}'.format (m.silhouette_score(X, labels, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.0. Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:13:04.821847Z",
     "start_time": "2022-02-15T18:13:04.808637Z"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:13:25.468781Z",
     "start_time": "2022-02-15T18:13:25.463501Z"
    }
   },
   "outputs": [],
   "source": [
    "df9 = X.copy()\n",
    "df9['cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:13:33.378151Z",
     "start_time": "2022-02-15T18:13:33.365591Z"
    }
   },
   "outputs": [],
   "source": [
    "#df9 = df4.copy()\n",
    "#df9['cluster'] = labels\n",
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Visualization Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:14:13.691460Z",
     "start_time": "2022-02-15T18:14:13.356290Z"
    }
   },
   "outputs": [],
   "source": [
    "#from plotly import express as px\n",
    "#fig = px.scatter_3d(df9, x='recency_days', y='invoice_no', z='gross_revenue', color='cluster')\n",
    "#fig.show()\n",
    "\n",
    "#visualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick')\n",
    "#visualizer.fit(X)\n",
    "#viausalizer.finalize()\n",
    "\n",
    "sns.scatterplot( x='embedding_x', y='embedding_y', hue='cluster', data=df9, palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. 2d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T17:15:53.956138Z",
     "start_time": "2022-02-15T17:15:53.953337Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_viz = df9.drop( columns = 'customer_id', axis=1)\n",
    "#sns.pairplot(df_viz, hue='cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. UMAP -t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:14:54.768784Z",
     "start_time": "2022-02-15T18:14:44.080866Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#!pip install llvmlite==0.37.0rc2 --ignore-installed\n",
    "#!pip install umap-learn\n",
    "#import umap.umap_ as umap\n",
    "\n",
    "# UMAP: cluster designed with high dimensionality\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=90, random_state=42)\n",
    "embedding = reducer.fit_transform(X)\n",
    "\n",
    "#embedding\n",
    "df_viz['embedding_x'] = embedding[:, 0]\n",
    "df_viz['embedding_y'] = embedding[:, 1]\n",
    "\n",
    "# plot UMAP\n",
    "sns.scatterplot(x='embedding_x',\n",
    "                y='embedding_y',\n",
    "                hue='cluster',\n",
    "                palette=sns.color_palette('hls',\n",
    "                                          n_colors=len(\n",
    "                                              df_viz['cluster'].unique())),\n",
    "                data=df_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "lang": "fr"
   },
   "source": [
    "## 9.2. Cluster Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:15:32.913586Z",
     "start_time": "2022-02-15T18:15:32.866423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of customer\n",
    "df_cluster = df9[['customer_id', 'cluster']].groupby('cluster').count().reset_index()\n",
    "df_cluster['perc_customer'] = 100*(df_cluster['customer_id']/df_cluster['customer_id'].sum())\n",
    "\n",
    "# Avg gross revenue\n",
    "df_avg_gross_revenue = df9[['gross_revenue', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_gross_revenue, how = 'inner', on ='cluster')\n",
    "\n",
    "# Avg recency days\n",
    "df_avg_recency_days = df9[['recency_days', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_recency_days, how = 'inner', on ='cluster')\n",
    "\n",
    "# Quantity Products\n",
    "df_avg_quantity_products = df9[['quantity_products', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_quantity_products, how = 'inner', on ='cluster')\n",
    "\n",
    "# Frequency\n",
    "df_avg_frequency = df9[['frequency', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_frequency, how = 'inner', on ='cluster')\n",
    "\n",
    "# Quantity Returns\n",
    "df_avg_quantity_returns = df9[['quantity_returns', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_quantity_returns, how = 'inner', on ='cluster')\n",
    "\n",
    "df_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T19:53:22.675104Z",
     "start_time": "2022-02-08T19:53:22.664655Z"
    }
   },
   "source": [
    "**Cluster 1: Insider Candidate**\n",
    "- Number of customers: 6 (0,14% of customers)\n",
    "- Average Recency: 7 days\n",
    "- Average Purchase: 89 \n",
    "- Avarage Revenue: $ 182.182,00 dollars\n",
    "- Avarage Ticket: $ 253,62\n",
    "\n",
    "**Cluster 0:**\n",
    "- Number of customers: 28 (0,64% of customers)\n",
    "- Average Recency: 6 days\n",
    "- Average Purchase: 57 \n",
    "- Avarage Revenue: $ 42.614,38 dollars  \n",
    "- Avarage Ticket: $ 162,86\n",
    "\n",
    "    \n",
    "**Cluster 3:**\n",
    "- Number of customers: 269 (6,15% of customers)\n",
    "- Average Recency: 20 days\n",
    "- Average Purchase: 19 \n",
    "- Avarage Revenue: $ 944, 95 dollars\n",
    "- Avarage Ticket: $ 62,47\n",
    "\n",
    "\n",
    "**Cluster 2:**\n",
    "- Number of customers: 4069 (93,06% of customers)\n",
    "- Average Recency: 92 days\n",
    "- Average Purchase: 4 \n",
    "- Avarage Revenue: $ 1.372,57 dollars  \n",
    "- Avarage Ticket: $ 25.36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.0. Deploy to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
