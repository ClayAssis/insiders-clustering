{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= 'blue'> Project: High Value Customer Identification (Insiders)</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T12:53:24.629168Z",
     "start_time": "2022-02-07T12:53:24.622757Z"
    }
   },
   "source": [
    "## Business Challange\n",
    "\n",
    "A loyalty program of customers to increase sales frquency.\n",
    "\n",
    "## Business Planning (IOT)\n",
    "\n",
    "### Input \n",
    "    1. Business Problem\n",
    "        - Select the most valuable customers to join a loyalty program.\n",
    "    \n",
    "    2. Dataset\n",
    "        - One year e-commerce sales.\n",
    "        Invoice No: Invoice number (A 6-digit integral number uniquely assigned to each transaction)\n",
    "\n",
    "        Stock Code: Product (item) code\n",
    "\n",
    "        Description: Product (item) name\n",
    "\n",
    "        Quantity: The quantities of each product (item) per transaction\n",
    "\n",
    "        Invoice Date: The day when each transaction was generated\n",
    "\n",
    "        Unit Price: Unit price (Product price per unit)\n",
    "\n",
    "        Customer ID: Customer number (Unique ID assigned to each customer)\n",
    "\n",
    "        Country: Country name (The name of the country where each customer resides)\n",
    "    \n",
    "### Output\n",
    "    1. Indicate customers who will be part of a loyalty program called Insiders.\n",
    "            - List: client_id | is_insider\n",
    "                        10323 |   yes\n",
    "                        32413 |   no\n",
    "    2. A report with the answers for the business questions.\n",
    "    - Who are the customers eligible to join the program?\n",
    "    - How many customers will be part os this group?\n",
    "    - What are the main characteristics of these customers?\n",
    "    - What is the contribution percentage revenue from Insiders?\n",
    "    - What is the group's revenue expectation for the coming months?\n",
    "    - What are the condictions for select customers to join Insiders?\n",
    "    - What are the condictions for removing Insiders customers?\n",
    "    - What is the guarantee that the Insiders program is better than the rest of the base?\n",
    "    - What actions can the marketing team take to increase revenue?\n",
    "    \n",
    "### Taks\n",
    "    1. Who are the customers eligible to join the program?\n",
    "        - What does it mean, to be elegible? What does high-value customers mean?\n",
    "             - Revenue: ticket, bascket size, high LTV (Lifetime Value), churn probability,high TVC prevision, purchasing propensity.\n",
    "             - Cost: lower return rate.\n",
    "             - Purchase experience: high average evaluation rate.\n",
    "     \n",
    "    2. How many customers will be part os this group?\n",
    "        - Total nambers of customers.\n",
    "        - % Insiders group.\n",
    "        \n",
    "    3. What are the main characteristics of these customers?\n",
    "        - Age\n",
    "        - Location\n",
    "        - Others characteristics.\n",
    "        - Ticket, bascket size, high LTV, churn probability,high TVC prevision, purchasing propensity.\n",
    "        \n",
    "    4. What is the contribution percentage revenue from Insiders?\n",
    "         - Total revenue for the year.\n",
    "         - Insiders group revenue.\n",
    "         \n",
    "    5. What is the group's revenue expectation for the coming months?\n",
    "        - LTV Insisders group.\n",
    "        - Cohort analysis.\n",
    "        \n",
    "    6. What are the condictions for select customers to join Insiders?\n",
    "        - Define the periodicity\n",
    "        - The person needs to have similar characteristics with someone in the group.\n",
    "    \n",
    "    7. What are the condictions for removing Insiders customers?\n",
    "        - Define the periodicity\n",
    "        - The person doen't need to have similar characteristics with someone in the group.\n",
    "        \n",
    "    8. What is the guarantee that the Insiders program is better than the rest of the base?\n",
    "        - A/B test\n",
    "        - A/B bayesian test\n",
    "        - Hypothesis test\n",
    "        \n",
    "    9. What actions can the marketing team take to increase revenue?\n",
    "        - Discont\n",
    "        - Purchase preference\n",
    "        - Purchase shipping\n",
    "        - Company visit  \n",
    "        \n",
    "## Benchmark Solutions\n",
    "\n",
    "###  Desk Research\n",
    " - RFM model (recency, frequency,, monetary): sorted data to have a RFM Score.\n",
    " \n",
    "     Recency: How recently a customer has made a purchase\n",
    "     \n",
    "     Frequency: How often a customer makes a purchase\n",
    "     \n",
    "     Monetary Value: How much money a customer spends on purchases\n",
    "     \n",
    "\n",
    " - example project: https://guillaume-martin.github.io/rfm-segmentation-with-python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:37.438964Z",
     "start_time": "2022-02-12T16:54:37.424188Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image, HTML\n",
    "from datetime import datetime\n",
    "from sklearn import cluster as c\n",
    "from sklearn import metrics as m\n",
    "from plotly import express as px\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:39.307798Z",
     "start_time": "2022-02-12T16:54:39.272675Z"
    }
   },
   "outputs": [],
   "source": [
    " def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()\n",
    "    \n",
    "jupyter_settings() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:41.146315Z",
     "start_time": "2022-02-12T16:54:40.645961Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df_raw = pd.read_csv('data/Ecommerce.csv')\n",
    "\n",
    "# drop extra column\n",
    "df_raw = df_raw.drop(columns = ['Unnamed: 8'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:41.190190Z",
     "start_time": "2022-02-12T16:54:41.159129Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:41.548280Z",
     "start_time": "2022-02-12T16:54:41.541029Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_new = ['invoice_no', 'stock_code', 'description', 'quantity', 'invoice_date',\n",
    "       'unit_price', 'customer_id', 'country']\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T19:34:06.250066Z",
     "start_time": "2022-02-07T19:34:06.246803Z"
    }
   },
   "source": [
    "## 1.2. Data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:41.931704Z",
     "start_time": "2022-02-12T16:54:41.923744Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of Rows: {}'.format(df1.shape[0]))\n",
    "print('Number of Columns: {}'.format(df1.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:42.317627Z",
     "start_time": "2022-02-12T16:54:42.308004Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:42.548568Z",
     "start_time": "2022-02-12T16:54:42.484953Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['invoice_no'] = df1['invoice_no'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:42.724118Z",
     "start_time": "2022-02-12T16:54:42.687919Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['stock_code'] = df1['stock_code'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:43.207365Z",
     "start_time": "2022-02-12T16:54:43.080986Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Replace NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:43.579499Z",
     "start_time": "2022-02-12T16:54:43.475235Z"
    }
   },
   "outputs": [],
   "source": [
    "df_missing = df1.loc[df1['customer_id'].isna(),:]\n",
    "df_not_missing = df1.loc[~df1['customer_id'].isna(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:43.949047Z",
     "start_time": "2022-02-12T16:54:43.676913Z"
    }
   },
   "outputs": [],
   "source": [
    "# create reference\n",
    "df_backup = pd.DataFrame(df_missing['invoice_no'].drop_duplicates())\n",
    "df_backup['customer_id'] = np.arange(19000, 19000+len(df_backup),1)\n",
    "\n",
    "# merge original with reference dataframe\n",
    "df1 = pd.merge(df1, df_backup, on = 'invoice_no', how= 'left')\n",
    "\n",
    "# coalesce\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first(df1['customer_id_y'])\n",
    "\n",
    "# drop extra columns\n",
    "df1 = df1.drop(columns=['customer_id_x','customer_id_y'], axis=1)\n",
    "   \n",
    "df1.head()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:44.037670Z",
     "start_time": "2022-02-12T16:54:43.950279Z"
    }
   },
   "outputs": [],
   "source": [
    "# No NaN in 'customer_id'\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Change dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:44.364655Z",
     "start_time": "2022-02-12T16:54:44.253251Z"
    }
   },
   "outputs": [],
   "source": [
    "# invoice_date\n",
    "df1[\"invoice_date\"] = pd.to_datetime(df1[\"invoice_date\"],infer_datetime_format=True)\n",
    "\n",
    "# customer_id\n",
    "df1['customer_id'] = df1['customer_id'].astype(int)\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:44.722570Z",
     "start_time": "2022-02-12T16:54:44.647224Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes(include =['int64', 'float64'])\n",
    "cat_attributes = df1.select_dtypes(exclude = ['int64', 'float64', 'datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:44.931949Z",
     "start_time": "2022-02-12T16:54:44.847984Z"
    }
   },
   "outputs": [],
   "source": [
    " # central tendency - mean, median\n",
    "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "             \n",
    "# dispersion - desvio padrÃ£o, minimo, maximo, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T\n",
    "d2 = pd.DataFrame( num_attributes.apply( np.min ) ).T\n",
    "d3 = pd.DataFrame( num_attributes.apply( np.max ) ).T\n",
    "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T\n",
    "\n",
    "# concatenate\n",
    "m = pd.concat( [d2, d3, d4, ct1, ct2, d1, d5, d6] ).T.reset_index()\n",
    "m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'mediana', 'std', 'skew', 'kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.1.1. Numerical Attributes - Investigating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T17:48:46.911147Z",
     "start_time": "2022-02-09T17:48:46.903035Z"
    }
   },
   "source": [
    "1. Could be negative quantity, return?\n",
    "2. Unit price = 0. Could it be sales?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.2. Categorical Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoice number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:46.355526Z",
     "start_time": "2022-02-12T16:54:45.852405Z"
    }
   },
   "outputs": [],
   "source": [
    "#cat_attributes['invoice_no'].astype(int)  -> Data contains 'invoice_no' with numbers and letters.\n",
    "df_letter_invoices = df1.loc[df1['invoice_no'].apply(lambda x: bool(re.search( '[^0-9]+', x ))), :]\n",
    "len(df_letter_invoices)\n",
    "\n",
    "print('Total number of invoices:{}'.format(len(df_letter_invoices)))\n",
    "print('Total number os negative quantity:{}'.format(len(df_letter_invoices[df_letter_invoices['quantity']< 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:46.788531Z",
     "start_time": "2022-02-12T16:54:46.356617Z"
    }
   },
   "outputs": [],
   "source": [
    "# check stock codes only characters\n",
    "df1.loc[df1['stock_code'].apply( lambda x: bool( re.search( '^[a-zA-Z]+$', x ) ) ), 'stock_code'].unique()\n",
    "\n",
    "# Action:\n",
    "## 1. Remove stock_code in ['POST', 'D', 'M', 'PADS', 'DOT', 'CRUK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:46.791686Z",
     "start_time": "2022-02-12T16:54:46.789839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Action: Delete description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:47.153361Z",
     "start_time": "2022-02-12T16:54:47.097573Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df1['country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:47.419074Z",
     "start_time": "2022-02-12T16:54:47.321508Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['country'].value_counts(normalize = True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:47.614399Z",
     "start_time": "2022-02-12T16:54:47.546160Z"
    }
   },
   "outputs": [],
   "source": [
    "df1[['customer_id', 'country']].drop_duplicates().groupby('country').count().reset_index().sort_values('customer_id', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0. Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:48.060741Z",
     "start_time": "2022-02-12T16:54:48.008760Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:48.459727Z",
     "start_time": "2022-02-12T16:54:48.447406Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:48.918777Z",
     "start_time": "2022-02-12T16:54:48.683622Z"
    }
   },
   "outputs": [],
   "source": [
    "# === Numerical attributes ====\n",
    "df2 = df2.loc[df2['unit_price'] >= 0.04, :]\n",
    "\n",
    "# === Categorical attributes ====\n",
    "df2 = df2[~df2['stock_code'].isin( ['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY', 'DCGSSGIRL', 'PADS', 'B', 'CRUK'] ) ]\n",
    "\n",
    "# description\n",
    "df2 = df2.drop( columns='description', axis=1 )\n",
    "\n",
    "# map -  \n",
    "df2 = df2[~df2['country'].isin( ['European Community', 'Unspecified' ] ) ]\n",
    "\n",
    "# bad users\n",
    "#df2 = df2[~df2['customer_id'].isin( [16446] )]\n",
    "\n",
    "# quantity\n",
    "df2_returns = df2.loc[df1['quantity'] < 0, :]\n",
    "df2_purchase = df2.loc[df1['quantity'] >= 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:49.440708Z",
     "start_time": "2022-02-12T16:54:49.397015Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:49.837812Z",
     "start_time": "2022-02-12T16:54:49.832955Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Ideas:\n",
    "## 1) Moving Average - 7d, 14d, 30d\n",
    "## 2) Purchase quantity by month, before the 15th and after the 15th.\n",
    "## 3) Average Financial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:50.301399Z",
     "start_time": "2022-02-12T16:54:50.239419Z"
    }
   },
   "outputs": [],
   "source": [
    "# data reference\n",
    "df_ref = df3.drop(['invoice_no', 'stock_code', 'quantity', 'invoice_date', 'unit_price', 'country'],\n",
    "                   axis =1 ).drop_duplicates( ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:50.822575Z",
     "start_time": "2022-02-12T16:54:50.758091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gross Revenue\n",
    "df2_purchase.loc[:,'gross_revenue'] = df2_purchase.loc[:,'quantity'] * df2_purchase.loc[:,'unit_price']\n",
    "\n",
    "# Monetary\n",
    "df_monetary = df2_purchase.loc[:,['customer_id', 'gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "df_ref = pd.merge(df_ref, df_monetary, on = 'customer_id', how = 'left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Recency - Day from last purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:51.292770Z",
     "start_time": "2022-02-12T16:54:51.240785Z"
    }
   },
   "outputs": [],
   "source": [
    " # Recency - Last day purchase\n",
    "df_recency = df2_purchase.loc[:, ['customer_id', 'invoice_date']].groupby( 'customer_id' ).max().reset_index()\n",
    "df_recency['recency_days'] = ( df2['invoice_date'].max() - df_recency['invoice_date'] ).dt.days\n",
    "df_recency = df_recency[['customer_id', 'recency_days']].copy()\n",
    "df_ref = pd.merge( df_ref, df_recency, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Quantity of purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:52.064233Z",
     "start_time": "2022-02-12T16:54:51.975273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Frequency - It depens on product returns\n",
    "df_freq =(df2_purchase.loc[:,['customer_id', 'invoice_no']].drop_duplicates()\n",
    "                                                          .groupby('customer_id')\n",
    "                                                          .count()\n",
    "                                                          .reset_index()\n",
    "                                                          .rename(columns={'invoice_no': 'quantity_invoices'}))\n",
    "df_ref = pd.merge( df_ref, df_freq, on = 'customer_id', how ='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4. Quantity of items purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:53.054759Z",
     "start_time": "2022-02-12T16:54:53.011816Z"
    }
   },
   "outputs": [],
   "source": [
    "df_freq = (df2_purchase.loc[:,['customer_id', 'quantity']].groupby('customer_id')\n",
    "                                                        .sum()\n",
    "                                                        .reset_index()\n",
    "                                                        .rename(columns={'quantity': 'quantity_items'}))\n",
    "                                                        \n",
    "                                                        \n",
    "df_ref = pd.merge( df_ref, df_freq, on = 'customer_id', how ='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5. Quantity of products purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:54.037617Z",
     "start_time": "2022-02-12T16:54:53.963783Z"
    }
   },
   "outputs": [],
   "source": [
    "df_freq = (df2_purchase.loc[:,['customer_id', 'stock_code']].groupby('customer_id')\n",
    "                                                        .count()\n",
    "                                                        .reset_index()\n",
    "                                                        .rename(columns={'stock_code': 'quantity_products'}))\n",
    "                                                        \n",
    "                                                        \n",
    "df_ref = pd.merge( df_ref, df_freq, on = 'customer_id', how ='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 .1.6. Average Ticket Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:54.602848Z",
     "start_time": "2022-02-12T16:54:54.560970Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average Ticket\n",
    "df_avg_ticket = df2_purchase[['customer_id', 'gross_revenue']].groupby('customer_id').mean().reset_index().rename(columns={'gross_revenue': 'avg_ticket'})\n",
    "df_ref = pd.merge( df_ref, df_avg_ticket, on = 'customer_id', how = 'left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7. Average Recency Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:55.520372Z",
     "start_time": "2022-02-12T16:54:55.042376Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average recency days\n",
    "df_aux = df2[['customer_id', 'invoice_date']].drop_duplicates().sort_values(['customer_id', 'invoice_date'], ascending=['False', 'False'])\n",
    "df_aux['next_customer_id'] = df_aux['customer_id'].shift() # next customer\n",
    "df_aux['previous_date'] = df_aux['invoice_date'].shift() # next invoice date\n",
    "\n",
    "df_aux['avg_recency_days'] = df_aux.apply(lambda x: (x['invoice_date'] - x['previous_date']).days if x['customer_id'] ==x['next_customer_id'] else np.nan, axis=1 )\n",
    "\n",
    "df_aux = df_aux.drop( ['invoice_date', 'next_customer_id', 'previous_date'], axis=1 ).dropna()\n",
    "\n",
    "# average recency\n",
    "df_avg_recency_days = df_aux.groupby( 'customer_id' ).mean().reset_index()\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge(df_ref, df_avg_recency_days, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.8. Frequency Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:56.157176Z",
     "start_time": "2022-02-12T16:54:55.564959Z"
    }
   },
   "outputs": [],
   "source": [
    "df_aux = ( df2_purchase[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates()\n",
    "                                                             .groupby( 'customer_id')\n",
    "                                                             .agg( max_ = ( 'invoice_date', 'max' ), \n",
    "                                                                   min_ = ( 'invoice_date', 'min' ),\n",
    "                                                                   days_= ( 'invoice_date', lambda x: ( ( x.max() - x.min() ).days ) + 1 ),\n",
    "                                                                   buy_ = ( 'invoice_no', 'count' ) ) ).reset_index()\n",
    "# Frequency\n",
    "df_aux['frequency'] = df_aux[['buy_', 'days_']].apply( lambda x: x['buy_'] / x['days_'] if  x['days_'] != 0 else 0, axis=1 )\n",
    "\n",
    "# Merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'frequency']], on='customer_id', how='left' )\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.9. Number of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:56.228906Z",
     "start_time": "2022-02-12T16:54:56.220692Z"
    }
   },
   "outputs": [],
   "source": [
    "df2_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:56.462274Z",
     "start_time": "2022-02-12T16:54:56.447965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of Returns\n",
    "df_returns = df2_returns[['customer_id', 'quantity']].groupby( 'customer_id' ).sum().reset_index().rename( columns={'quantity':'quantity_returns'} )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:56.686871Z",
     "start_time": "2022-02-12T16:54:56.663610Z"
    }
   },
   "outputs": [],
   "source": [
    "df_returns['quantity_returns'] = df_returns['quantity_returns'] * -1\n",
    "\n",
    "df_ref = pd.merge( df_ref, df_returns, how='left', on='customer_id' )\n",
    "df_ref.loc[df_ref['quantity_returns'].isna(), 'quantity_returns'] = 0\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.0. Basket Size - Quantity items per basket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Invoice No = purchase\n",
    "- Stock Code = product\n",
    "- Quantity = Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:57.658525Z",
     "start_time": "2022-02-12T16:54:57.551453Z"
    }
   },
   "outputs": [],
   "source": [
    "df_aux = (df2_purchase.loc[:,['customer_id', 'invoice_no', 'quantity']].groupby('customer_id')\n",
    "                                                           .agg(n_purchase=('invoice_no', 'nunique'),\n",
    "                                                                n_products=('quantity', 'sum'))\n",
    "                                                            .reset_index())\n",
    "# calculation\n",
    "df_aux['avg_basket_size'] = df_aux['n_products']/df_aux['n_purchase']\n",
    "\n",
    "#merge\n",
    "df_ref = pd.merge(df_ref, df_aux[['customer_id', 'avg_basket_size']], how='left', on='customer_id')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Unique Basket Size - Quantity of differents products per purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Invoice No = purchase\n",
    "- Stock Code = product\n",
    "- Quantity = Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:59.050856Z",
     "start_time": "2022-02-12T16:54:58.937238Z"
    }
   },
   "outputs": [],
   "source": [
    "df_aux = (df2_purchase.loc[:,['customer_id', 'invoice_no', 'stock_code']].groupby('customer_id')\n",
    "                                                           .agg(n_purchase=('invoice_no', 'nunique'),\n",
    "                                                                n_products=('stock_code', 'count'))\n",
    "                                                            .reset_index())\n",
    "# calculation\n",
    "df_aux['avg_unique_basket_size'] = df_aux['n_products']/df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge(df_ref, df_aux[['customer_id', 'avg_unique_basket_size']], how='left', on='customer_id')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:54:59.412677Z",
     "start_time": "2022-02-12T16:54:59.385482Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:55:01.051866Z",
     "start_time": "2022-02-12T16:55:01.030006Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df_ref.dropna()\n",
    "df4.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:51:58.024737Z",
     "start_time": "2022-02-12T16:51:37.136440Z"
    }
   },
   "outputs": [],
   "source": [
    "#from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport (df4)\n",
    "profile.to_file('output.html')\n",
    "\n",
    "# to visualize: /output.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T16:55:05.085391Z",
     "start_time": "2022-02-12T16:55:05.046338Z"
    }
   },
   "outputs": [],
   "source": [
    "df4.sort_values('gross_revenue', ascending=False).drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4.2. Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5.0. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T20:18:32.678492Z",
     "start_time": "2022-02-11T20:18:32.674485Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T20:18:32.903330Z",
     "start_time": "2022-02-11T20:18:32.898628Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T20:18:33.145082Z",
     "start_time": "2022-02-11T20:18:33.109628Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ss = pp.StandardScaler()\n",
    "\n",
    "df5['gross_revenue'] = ss.fit_transform(df5[['gross_revenue']])\n",
    "df5['recency_days'] = ss.fit_transform(df5[['recency_days']])\n",
    "df5['invoice_no'] = ss.fit_transform(df5[['invoice_no']])\n",
    "df5['avg_ticket'] = ss.fit_transform(df5[['avg_ticket']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T20:18:33.336198Z",
     "start_time": "2022-02-11T20:18:33.315856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 6.0. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T20:18:33.698833Z",
     "start_time": "2022-02-11T20:18:33.694951Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:36.368418Z",
     "start_time": "2022-02-10T20:27:36.072078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(np.log(df5['gross_revenue']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 7.0. Hyperparameter Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:36.934177Z",
     "start_time": "2022-02-10T20:27:36.927212Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = df6.drop(columns = ['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:37.174875Z",
     "start_time": "2022-02-10T20:27:37.160678Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:38.336848Z",
     "start_time": "2022-02-10T20:27:38.332467Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clusters = [2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 7.1. Within-Cluster Sum os Square (WSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:41.631534Z",
     "start_time": "2022-02-10T20:27:40.134552Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WSS: Within- CLuster Sum of Squares -> compactness\n",
    "wss = []\n",
    "for k in clusters:\n",
    "    # model definition\n",
    "    kmeans = c.KMeans(init='random', n_clusters=k, n_init=10, max_iter=300, random_state=42)\n",
    "    \n",
    "    # model training\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    # validation\n",
    "    wss.append(kmeans.inertia_)\n",
    "    \n",
    "\n",
    "plt.subplot(2, 1, 1 )\n",
    "# Plot wss - Elbow Method\n",
    "plt.plot(clusters, wss, linestyle='--', marker = 'o', color='b')\n",
    "plt.xlabel('K');\n",
    "plt.ylabel('Within-Cluster Sum of Square');\n",
    "plt.title('WSS vc k')\n",
    "\n",
    "plt.subplot(2, 1, 2 )\n",
    "#from yellowbrick.cluster import KElbowVisualizer\n",
    "kmeans = KElbowVisualizer( c.KMeans(), k=clusters, timings=False)\n",
    "kmeans.fit( X)\n",
    "kmeans.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 7.2. Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:43.557099Z",
     "start_time": "2022-02-10T20:27:41.632581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Silhoutte Score: is calculated using the mean intra-cluster distance ( a ) and the mean nearest-cluster distance ( b ) for each sample\n",
    "# Is about separation\n",
    "# Silhouette is better than Wss because takes into consideration the nearest-cluster distance.\n",
    "\n",
    "kmeans = KElbowVisualizer( c.KMeans(), k=clusters, metric='silhouette', timings=False)\n",
    "kmeans.fit( X)\n",
    "kmeans.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 7.1. Silhouette Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:47.713027Z",
     "start_time": "2022-02-10T20:27:43.558492Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "k=3\n",
    "fig, ax = plt.subplots(3,2, figsize=(25,18))\n",
    "for k in clusters:\n",
    "    km = c.KMeans( n_clusters=k, init='random', n_init=10, max_iter=100, random_state=42)\n",
    "    q, mod = divmod(k,2)\n",
    "    visualizer = SilhouetteVisualizer(km, colosr='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(X)\n",
    "    visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 8.1. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:47.803122Z",
     "start_time": "2022-02-10T20:27:47.714101Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "k = 3\n",
    "kmeans = c.KMeans(init='random', n_clusters=k, n_init=10, max_iter=300)\n",
    "\n",
    "# model training\n",
    "kmeans.fit(X)\n",
    "\n",
    "# clustering\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 8.2. Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:48.026451Z",
     "start_time": "2022-02-10T20:27:47.804219Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WSS (Within- cluster sum of square)\n",
    "print('WSS value: {}'.format( kmeans.inertia_))\n",
    "\n",
    "from sklearn import metrics as m\n",
    "# SS (Silhouette Score)\n",
    "print('SS value: {}'.format (m.silhouette_score(X, labels, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 9.0. Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:27:48.034835Z",
     "start_time": "2022-02-10T20:27:48.028273Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df9 = df6.copy()\n",
    "df9['cluster'] = labels\n",
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 9.1. Visualization Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:24:35.019231Z",
     "start_time": "2022-02-10T20:24:34.338544Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#from plotly import express as px\n",
    "#fig = px.scatter_3d(df9, x='recency_days', y='invoice_no', z='gross_revenue', color='cluster')\n",
    "#fig.show()\n",
    "\n",
    "visualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick')\n",
    "visualizer.fit(X)\n",
    "viausalizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 9.2. 2d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:24:41.328549Z",
     "start_time": "2022-02-10T20:24:35.321353Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_viz = df9.drop( columns = 'customer_id', axis=1)\n",
    "sns.pairplot(df_viz, hue='cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 9.4. UMAP -t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:24:54.558385Z",
     "start_time": "2022-02-10T20:24:41.329681Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#!pip install llvmlite==0.37.0rc2 --ignore-installed\n",
    "#!pip install umap-learn\n",
    "#import umap.umap_ as umap\n",
    "\n",
    "# UMAP: cluster designed with high dimensionality\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=90, random_state=42)\n",
    "embedding = reducer.fit_transform(X)\n",
    "\n",
    "#embedding\n",
    "df_viz['embedding_x'] = embedding[:, 0]\n",
    "df_viz['embedding_y'] = embedding[:, 1]\n",
    "\n",
    "# plot UMAP\n",
    "sns.scatterplot(x='embedding_x',\n",
    "                y='embedding_y',\n",
    "                hue='cluster',\n",
    "                palette=sns.color_palette('hls',\n",
    "                                          n_colors=len(\n",
    "                                              df_viz['cluster'].unique())),\n",
    "                data=df_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": true,
    "lang": "fr"
   },
   "source": [
    "## 9.2. Profil de grappe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T20:28:02.000368Z",
     "start_time": "2022-02-10T20:28:01.948300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Number of customer\n",
    "df_cluster = df9[['customer_id', 'cluster']].groupby('cluster').count().reset_index()\n",
    "df_cluster['perc_customer'] = 100*(df_cluster['customer_id']/df_cluster['customer_id'].sum())\n",
    "\n",
    "# Avg gross revenue\n",
    "df_avg_gross_revenue = df9[['gross_revenue', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_gross_revenue, how = 'inner', on ='cluster')\n",
    "\n",
    "# Avg recency days\n",
    "df_avg_recency_days = df9[['recency_days', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_recency_days, how = 'inner', on ='cluster')\n",
    "\n",
    "# Avg invoice_no\n",
    "df_avg_invoice_no = df9[['invoice_no', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_invoice_no, how = 'inner', on ='cluster')\n",
    "\n",
    "# Avg ticket\n",
    "df_avg_ticket = df9[['avg_ticket', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, how = 'inner', on ='cluster')\n",
    "\n",
    "df_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T19:53:22.675104Z",
     "start_time": "2022-02-08T19:53:22.664655Z"
    },
    "hidden": true
   },
   "source": [
    "**Cluster 1: Insider Candidate**\n",
    "- Number of customers: 6 (0,14% of customers)\n",
    "- Average Recency: 7 days\n",
    "- Average Purchase: 89 \n",
    "- Avarage Revenue: $ 182.182,00 dollars\n",
    "- Avarage Ticket: $ 253,62\n",
    "\n",
    "**Cluster 0:**\n",
    "- Number of customers: 28 (0,64% of customers)\n",
    "- Average Recency: 6 days\n",
    "- Average Purchase: 57 \n",
    "- Avarage Revenue: $ 42.614,38 dollars  \n",
    "- Avarage Ticket: $ 162,86\n",
    "\n",
    "    \n",
    "**Cluster 3:**\n",
    "- Number of customers: 269 (6,15% of customers)\n",
    "- Average Recency: 20 days\n",
    "- Average Purchase: 19 \n",
    "- Avarage Revenue: $ 944, 95 dollars\n",
    "- Avarage Ticket: $ 62,47\n",
    "\n",
    "\n",
    "**Cluster 2:**\n",
    "- Number of customers: 4069 (93,06% of customers)\n",
    "- Average Recency: 92 days\n",
    "- Average Purchase: 4 \n",
    "- Avarage Revenue: $ 1.372,57 dollars  \n",
    "- Avarage Ticket: $ 25.36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.0. Deploy to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
